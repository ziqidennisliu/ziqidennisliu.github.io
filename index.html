<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ziqi Liu åˆ˜å­ç¦ </title> <meta name="author" content="Ziqi Liu åˆ˜å­ç¦"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%8A&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ziqidennisliu.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">ABOUT <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">PROJECTS </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">PUBLICATIONS </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">GALLERY </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">CONTACT </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post about-page"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Ziqi Liu</span> åˆ˜å­ç¦ </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mypic-480.webp 480w,/assets/img/mypic-800.webp 800w,/assets/img/mypic-1400.webp 1400w," type="image/webp" sizes="(min-width: 1000px) 242.5px, (min-width: 576px) 25vw, 95vw"> <img src="/assets/img/mypic.jpg?e0fef41a52072cb1b904c6b4928ddecb" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="mypic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div class="profile-icons"> <a href="mailto:ziqidennisliu@outlook.com" title="Email"><i class="fa-solid fa-envelope"></i></a> <a href="/assets/pdf/CV_ziqi_liu.pdf" title="CV" target="_blank" rel="noopener"><span class="cv-badge">CV</span></a> <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=_BNUuqUAAAAJ" title="Google Scholar" target="_blank" rel="noopener"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/ziqidennisliu" title="GitHub" target="_blank" rel="noopener"><i class="fa-brands fa-github"></i></a> <a href="https://linkedin.com/in/ziqi-liu-b064b5393" title="LinkedIn" target="_blank" rel="noopener"><i class="fa-brands fa-linkedin"></i></a> </div> </div> </div> <div class="clearfix"> <p>Hi! Iâ€™m <strong>Ziqi Liu</strong> åˆ˜å­ç¦</p> <p>Iâ€™m a first-year M.phil student at the <a href="https://qijiashao.github.io/team/" rel="external nofollow noopener" target="_blank">UbiquitousX Lab</a> at <a href="https://hkust.edu.hk/" rel="external nofollow noopener" target="_blank">Hong Kong University of Science and Technology</a>, supervised by <a href="https://qijiashao.github.io/" rel="external nofollow noopener" target="_blank">Qijia Shao</a>. Prior to HKUST, I got my B.Eng degree at <a href="https://www.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">Tsinghua University</a>, supervised by <a href="https://pi.cs.tsinghua.edu.cn/lab/people/YuntaoWang/en/" rel="external nofollow noopener" target="_blank">Yuntao Wang</a> and <a href="https://www.milab.design/team-1/mi-haipeng" rel="external nofollow noopener" target="_blank">Haipeng Mi</a>.</p> <p>My research focuses on the synergy between AI-driven sensing and adaptive intervention. By integrating hardware and software innovations across ubiquitous devices and wearables, I design and develop closed-loop systems that tightly couple the <strong>implicit, continuous sensing</strong> of behavioral and physiological states with <strong>just-in-time, context-aware interventions</strong>.</p> <p>I have gained valuable research experience in multiple esteemed labs, inlucding <a href="https://thfl.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">the Future Lab</a> and <a href="https://pi.cs.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">Pervasive HCI Group</a> at Tsinghua University.</p> </div> <div class="about-section-research"> <h2>Research Interests</h2> <div class="research-interests"> <div class="research-interests-grid"> <div class="research-interest-card"> <div class="research-interest-img"> <img src="/assets/img/ri_sensing.svg" alt="Pervasive Sensing" loading="lazy"> </div> <h3>Pervasive Sensing</h3> <div class="ri-card-desc">Acquiring behavioral and physiological signals through two complementary approaches: <ul> <li> <b>Everyday devices</b> â€” repurposing built-in sensors to capture rich signals during natural interaction.</li> <li> <b>Custom wearables</b> â€” designing devices that unobtrusively collect modalities beyond commodity hardware.</li> </ul> </div> </div> <div class="research-interest-card"> <div class="research-interest-img"> <img src="/assets/img/ri_inference.svg" alt="Personalized State Inference" loading="lazy"> </div> <h3>Personalized State Inference</h3> <div class="ri-card-desc">Transforming sensor data into user- and context-aware user-state estimates:: <ul> <li> <b>Interaction intent</b> â€” recognizing implicit goals and attention patterns for interaction applications.</li> <li> <b>Health &amp; cognitive states</b> â€” inferring physiological and psychological indicators for continuous health monitoring.</li> </ul> </div> </div> <div class="research-interest-card"> <div class="research-interest-img"> <img src="/assets/img/ri_intervention.svg" alt="Just-in-Time Intervention" loading="lazy"> </div> <h3>Just-in-Time Intervention</h3> <div class="ri-card-desc">Moving beyond always-on feedback by identifying, for each user and context, the precise moments when intervention is most beneficial. The system continuously evaluates situational cues and inferred user states to identify critical windows of need, then delivers personalized, context-sensitive support in both interaction and health domains. </div> </div> </div> </div> </div> <div class="about-section-news"> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Dec 08, 2025</th> <td> Our project â€œHand Motion Prediction for Adaptive Smartphone UI with Zero-permission Sensorsâ€ has won the <strong>Best Award</strong> for <a href="https://urop.hkust.edu.hk/whats_urop" rel="external nofollow noopener" target="_blank">UROP</a> at HKUST! Congrulations to Ziyi and the team! ğŸ‰ </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 08, 2025</th> <td> Spent a wonderful week at <strong>Mobicom 2025</strong> in Hong Kong as a student volunteer! ğŸ“¸ </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 15, 2025</th> <td> Arrived in Hong Kong and started my M.Phil at HKUST! ğŸŒŠ </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 22, 2025</th> <td> I have successfully graduated from Tsinghua University with a Bachelorâ€™s degree in Engineeringï¼ğŸ“ </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 05, 2025</th> <td> I passed my undergraduate thesis defenseï¼ğŸ—£ï¸ </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 23, 2025</th> <td> Our paper â€œ<strong>AroMR: Decentralizing Olfactory Displays into the Environment for Olfactory-Augmented Experiences in Mixed Reality</strong>â€ has been accepted to <strong>CHI 2025 Late Breaking Work</strong>! ğŸ‰ </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 17, 2025</th> <td> Our paper â€œ<strong>Enhancing Smartphone Eye Tracking with Cursor-Based Interactive Implicit Calibration</strong>â€ has been accepted to <strong>CHI 2025</strong>! ğŸ‰ </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 11, 2024</th> <td> Established a new wedsite for myself! ğŸ¥³ </td> </tr> </table> </div> </div> </div> <div class="about-section-pubs"> <h2> <a href="/publications/" style="color: inherit">Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cometic-480.webp 480w,/assets/img/publication_preview/cometic-800.webp 800w,/assets/img/publication_preview/cometic-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/cometic.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cometic.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10.1145/3706598.3713936" class="col-sm-8"> <div class="title">Enhancing Smartphone Eye Tracking with Cursor-Based Interactive Implicit Calibration</div> <div class="author"> Chang Liu,Â Xiangyang Wang,Â Chun Yu, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Yingtian Shi, Chongyang Wang, Ziqi Liu, Chen Liang, Yuanchun Shi' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</em>, , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3706598.3713936" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>The limited accuracy of eye-tracking on smartphones restricts its use. Existing RGB-camera-based eye-tracking relies on extensive datasets, which could be enhanced by continuous fine-tuning using calibration data implicitly collected from the interaction. In this context, we propose COMETIC (Cursor Operation Mediated Eye-Tracking Implicit Calibration), which introduces a cursor-based interaction and utilizes the inherent correlation between cursor and eye movement. By filtering valid cursor coordinates as proxies for the ground truth of gaze and fine-tuning the eye-tracking model with corresponding images, COMETIC enhances accuracy during the interaction. Both filtering and fine-tuning use pre-trained models and could be facilitated using personalized, dynamically updated data. Results show COMETIC achieves an average eye-tracking error of 278.3 px (1.60 cm, 2.29Â°), representing a 27.2% improvement compared to that without fine-tuning. We found that filtering cursor points whose actual distance to gaze is 150.0 px (0.86 cm) yields the best eye-tracking results.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/AroMR-480.webp 480w,/assets/img/publication_preview/AroMR-800.webp 800w,/assets/img/publication_preview/AroMR-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/AroMR.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="AroMR.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10.1145/3706599.3720290" class="col-sm-8"> <div class="title">AroMR: Decentralizing Olfactory Displays into the Environment for Olfactory-Augmented Experiences in Mixed Reality</div> <div class="author"> Yibo Wang,Â Ziqi Liu,Â Jiao Xue, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Qi Lu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3706599.3720290" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Smell, as a vital sensory modality, has the potential to significantly enhance user experience in immersive environments; however, its application in mixed reality (MR) remains underexplored. Current olfactory displays (ODs) are typically fixed to head-mounted displays (HMDs) as active olfactory inputs, limiting interaction and failing to capture the dynamic nature of human olfactory perception. To better integrate olfactory experiences into MR, we propose a "field-centric" strategy that decentralizes ODs into the physical environment as passive outputs. We further introduce AroMR, a proof-of-concept system that employs this strategy to incorporate olfactory feedback into MR experiences. A user study involving eight participants interacting with AroMR across three pre-designed scenarios revealed the potential of our approach to enhance engagement and create more immersive MR experiences. Based on these findings, we propose a conceptual design space to guide future research on integrating olfactory elements into MR.</p> </div> </div> </div> </li> </ol> </div> </div> <div style="margin-bottom: 6em;"></div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2026 Ziqi Liu åˆ˜å­ç¦. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>